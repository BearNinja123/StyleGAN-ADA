{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "former-tulsa",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understanding-halloween",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from layers import * # mod. conv, minibatch stdev, diffus, equalized layers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.losses import *\n",
    "from tqdm.notebook import tqdm\n",
    "import tensorflow.keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_addons as tfa\n",
    "import numpy.random as npr\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os, time, gc, random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expensive-reality",
   "metadata": {},
   "source": [
    "#### TimeIt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hired-cricket",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# custom class to see how long tasks take\n",
    "class timeIt:\n",
    "    def __init__(self, description):\n",
    "        self.start = time.time()\n",
    "        self.description = description\n",
    "        self.running = True\n",
    "    \n",
    "    def new(self, description, verbose=True):\n",
    "        self.start = time.time()\n",
    "        self.description = description\n",
    "        \n",
    "        duration = time.time() - startTime\n",
    "        if verbose:\n",
    "            print('{}; {:.4f} seconds to complete'.format(self.description, duration))\n",
    "        \n",
    "        return duration\n",
    "    \n",
    "    def close(self, verbose=True):\n",
    "        duration = time.time() - self.start\n",
    "        if verbose:\n",
    "            print('{}; {:.4f} seconds to complete'.format(self.description, duration))\n",
    "            \n",
    "        self.start = None\n",
    "        self.description = None\n",
    "        self.running = False\n",
    "        return duration\n",
    "\n",
    "sess = timeIt('testing timer')\n",
    "time.sleep(0.005)\n",
    "_ = sess.close(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuous-crazy",
   "metadata": {},
   "source": [
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "macro-advance",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# reals - numpy array of the training images; ds - batched TF dataset given to the GPU\n",
    "datasetPath = 'data'\n",
    "reals, ds = None, None\n",
    "gc.collect()\n",
    "\n",
    "batchSize = 8\n",
    "m = 2000 # amount of images stored in RAM (reduce if low RAM, increase if high RAM)\n",
    "m = min(m, int(1000 * len(os.listdir(dataSetPath))))\n",
    "\n",
    "m = batchSize * (m // batchSize)\n",
    "imgSize = 256 # size of images in pixels\n",
    "zdim = imgSize # number of elements in a latent vector\n",
    "p = 0.0 # probability of data augmentation\n",
    "n = 4 # number of minibatches before p is changed\n",
    "numImgsStep = 5e5 # number of images needed to change p from 0 -> 1 or 1 -> 0\n",
    "pStep = n * batchSize / numImgsStep # how much p increases/decreases per n minibatches\n",
    "eps = 1e-8 # epsilon, small number used to prevent NaN errors\n",
    "pplEMA = 0.0 # exponential moving average for average PPL for PPL reg."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quality-leave",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-symphony",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "\n",
    "'''\n",
    "goes into datasetPath, chooses and stores image data from random files (repeats allowed)\n",
    "into a np array, converts the array into the TF dataset\n",
    "\n",
    "Args:\n",
    "others - random indices for files to choose to train the GAN on\n",
    "verbose - determines whether duration to complete is printed out or not\n",
    "'''\n",
    "def loadData(others=None, verbose=True):\n",
    "    global reals, ds, m\n",
    "    sess = timeIt('Loading data')\n",
    "    os.chdir(datasetPath)\n",
    "    reals, ds = None, None\n",
    "    gc.collect()\n",
    "    expandM = int(np.sign(m%1000) + m // 1000)\n",
    "    files = os.listdir(datasetPath)\n",
    "    if others == None:\n",
    "        others = npr.randint(0, len(files), (expandM,)) # ceil(m / 1000)\n",
    "    \n",
    "    reals = np.zeros((1000 * expandM, imgSize, imgSize, 3))\n",
    "    for i in range(others.shape[0]):\n",
    "        strI = str(files[others[i]])\n",
    "        arr = np.load(strI)\n",
    "        reals[1000 * i: 1000 * (i + 1)] = arr\n",
    "        del arr\n",
    "    \n",
    "    reals = reals[:m].astype(np.float32)\n",
    "    \n",
    "    assert reals.shape[0] % batchSize == 0\n",
    "    assert type(reals) == np.ndarray\n",
    "    ds = (tf.data.Dataset.from_tensor_slices(reals).shuffle(3000).batch(batchSize))\n",
    "    ds = ds.prefetch(AUTO)\n",
    "    gc.collect()\n",
    "    sess.close(verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-score",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Augments a batch of images (imgs).\n",
    "Augmentations: brightness shifts, cropping & resizing, 90 degree rotation, general rotation, fractional translation\n",
    "(no color-changing augmentation since paper says those weren't very useful)\n",
    "'''\n",
    "def aug(imgs, p):\n",
    "    augImgs = imgs\n",
    "    def augCond(x):\n",
    "        randInds = tf.random.uniform((batchSize,))\n",
    "        trueCond = tf.cast(randInds < p, tf.float32) # using tf.cast to turn booleans into ones and zeros\n",
    "        falseCond = tf.cast(randInds >= p, tf.float32)\n",
    "        auged = x * tf.reshape(trueCond, (batchSize, 1, 1, 1)) + augImgs * tf.reshape(falseCond, (batchSize, 1, 1, 1))\n",
    "        return auged\n",
    "    \n",
    "    height = tf.random.uniform((), minval=0.5, maxval=1)\n",
    "    width = tf.random.uniform((), minval=0.5, maxval=1)\n",
    "    boxLite = tf.random.uniform((batchSize, 2), maxval=(1-height, 1-width))\n",
    "    boxes = tf.concat([boxLite, tf.transpose(boxLite[:, 0][np.newaxis]) + height, tf.transpose(boxLite[:, 1][np.newaxis]) + width], axis=1)\n",
    "    boxLiteIso = tf.random.uniform((batchSize, 1), maxval=1-height)\n",
    "    boxIso = tf.concat([boxLite, tf.transpose(boxLiteIso[:, 0][np.newaxis]) + height, tf.transpose(boxLiteIso[:, 0][np.newaxis]) + height], axis=1)\n",
    "    rot90s = np.pi * 90 * tf.cast(tf.random.uniform((batchSize,), minval=0, maxval=4, dtype=tf.int32), tf.float32) / 180\n",
    "    augImgs = augCond(tf.image.random_brightness(augImgs, max_delta=0.25))\n",
    "    augImgs = augCond(tf.image.crop_and_resize(augImgs, boxIso, tf.range(batchSize), (imgSize, imgSize), extrapolation_value=1))\n",
    "    augImgs = augCond(tf.image.crop_and_resize(augImgs, boxes, tf.range(batchSize), (imgSize, imgSize), extrapolation_value=1))\n",
    "    augImgs = augCond(tfa.image.rotate(augImgs, rot90s))\n",
    "    augImgs = augCond(tfa.image.rotate(augImgs, tf.random.uniform((batchSize,), minval=-np.pi/6, maxval=np.pi/6)))\n",
    "    augImgs = augCond(tfa.image.translate(augImgs, tf.random.normal((batchSize, 2), 0, imgSize // 10)))\n",
    "    return augImgs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flush-consensus",
   "metadata": {},
   "source": [
    "#### Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "northern-rocket",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Generator style block.\n",
    "Args:\n",
    "accum - accumulated output from the input/output skips\n",
    "x - the non-RGB image input\n",
    "w - the style (output of the mapping function with input of the latent vector)\n",
    "noiseInp - normally distributed noise\n",
    "filters - number of channels/feature maps the output of the style block will have\n",
    "us - whether or not to upsample the images\n",
    "'''\n",
    "def gblock(accum, x, w, noiseInp, filters, us=True):\n",
    "    if us:\n",
    "        x = DiffUS()(x) # using custom upsampling function since other upsampling methods didn't provide gradients of their gradients\n",
    "        accum = DiffUS()(accum)\n",
    "    \n",
    "    for i in range(2):\n",
    "        x = ConvMod(filters, x, w)([x, w])\n",
    "        noise = Lambda(crop_to_fit)([noiseInp, x]) # crop noises so it can be added with x\n",
    "        noise = FCE(filters, kernel_initializer=zeros, use_bias=False, lrelu=False)(noise) #scale noises\n",
    "        x = Add()([x, noise])\n",
    "        x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    trgb = ConvMod(3, x, w, 1, demod=False)([x, w]) # toRGB 1x1 convolution\n",
    "    accum = Add()([accum, trgb]) * np.sqrt(1 / 2) # the sqrt(1/2) not included in original StyleGAN2 but i didn't see why not\n",
    "        \n",
    "    return accum, x\n",
    "\n",
    "# Discriminator block.\n",
    "def dblock(x, filters, maxFilters=256):\n",
    "    frgb = CVE(min(2 * filters, maxFilters), 1, lrelu=False, use_bias=False)(x)\n",
    "    \n",
    "    x = CVE(filters)(x)\n",
    "    x = CVE(min(2 * filters, maxFilters))(x)\n",
    "        \n",
    "    frgb = AveragePooling2D()(frgb)\n",
    "    x = AveragePooling2D()(x)\n",
    "    x = Add()([x, frgb])\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "described-serve",
   "metadata": {},
   "source": [
    "#### Build models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-catalyst",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "nBlocks = int(np.log2(imgSize / 4)) # number of upsampled style blocks\n",
    "\n",
    "# mapper architecture\n",
    "def ztow(nlayers=8):\n",
    "    z = Input((zdim,))\n",
    "    w = z\n",
    "    if nlayers > 0:\n",
    "        w = LayerNormalization()(w)\n",
    "    for i in range(max(nlayers-1, 0)):\n",
    "        w = FCE(zdim)(w)\n",
    "    return Model(z, w, name='mapping')\n",
    "\n",
    "# generator architecture\n",
    "def genGen():\n",
    "    ws = [Input((zdim,), name='w{}'.format(i)) for i in range(nBlocks+1)]\n",
    "    noiseInp = Input((imgSize, imgSize, 1), name='noiseInp')\n",
    "\n",
    "    x = Dense(1)(ws[0]); x = Lambda(lambda x: x * 0 + 1)(x)\n",
    "    x = FCE(4*4*zdim, lrelu=False, use_bias=False)(x)\n",
    "    x = Reshape((4, 4, zdim))(x)\n",
    "    \n",
    "    layerFilters = (256, 256, 256, 128, 64, 32)\n",
    "    \n",
    "    x = ConvMod(layerFilters[0], x, ws[0])([x, ws[0]])\n",
    "    noise = Lambda(crop_to_fit)([noiseInp, x])\n",
    "    noise = FCE(layerFilters[0], kernel_initializer=zeros, use_bias=False, lrelu=False)(noise)\n",
    "    x = Add()([x, noise])\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    accum = ConvMod(3, x, ws[0], 1, demod=False)([x, ws[0]])\n",
    "    \n",
    "    for idx, f in enumerate(layerFilters):\n",
    "        accum, x = gblock(accum, x, ws[idx+1], noiseInp, f)\n",
    "        \n",
    "    out = CVE(3, 1, lrelu=False)(accum)\n",
    "    return Model([*ws, noiseInp], out, name='generator')\n",
    "      \n",
    "# discriminator architecture  \n",
    "def genDisc():\n",
    "    inp = Input((imgSize, imgSize, 3)); x = inp\n",
    "\n",
    "    layerFilters = (32, 64, 128, 256, 256, 256)\n",
    "    \n",
    "    x = CVE(layerFilters[0], 1)(x)\n",
    "    for fi, f in enumerate(layerFilters):\n",
    "        x = dblock(x, f, maxFilters=layerFilters[-1])\n",
    "    \n",
    "    x = Lambda(minibatchStd)(x)\n",
    "    x = CVE(layerFilters[-1])(x)\n",
    "    x = Flatten()(x)\n",
    "    x = FCE(layerFilters[-1])(x)\n",
    "    out = FCE(1, lrelu=False)(x)\n",
    "\n",
    "    return Model(inp, out, name='discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-snowboard",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "modelPath = 'models'\n",
    "fids, gcosts, dcosts = [], [], []\n",
    "pplNorms = []\n",
    "gpcosts = []\n",
    "ps, rts = [], []\n",
    "\n",
    "pretrained = True\n",
    "\n",
    "mapper = ztow()\n",
    "generator = genGen()\n",
    "discriminator = genDisc()\n",
    "inception = tf.keras.applications.InceptionV3(include_top=False, pooling='avg', input_shape=(imgSize, imgSize, 3)) # for FID score\n",
    "\n",
    "if pretrained:\n",
    "    p = np.load(os.path.join(modelPath, 'p.npy'))\n",
    "    mapper.load_weights(os.path.join(modelPath, 'mapWeights.h5'))\n",
    "    generator.load_weights(os.path.join(modelPath, 'genWeights.h5'))\n",
    "    discriminator.load_weights(os.path.join(modelPath, 'discWeights.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleased-tactics",
   "metadata": {},
   "source": [
    "#### Model summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precise-notion",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    mapper.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthetic-journal",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "important-senior",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greenhouse-morris",
   "metadata": {},
   "source": [
    "#### Optimizers and losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removed-yahoo",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "lr = 2e-3 * batchSize / 32\n",
    "mapOpt = Adam(lr / 100, epsilon=1e-8)\n",
    "genOpt = Adam(lr, 0, 0.9, epsilon=1e-8)\n",
    "discOpt = Adam(lr, 0, 0.9, epsilon=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fluid-functionality",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def rt(truePreds): # overfitting metric\n",
    "    return tf.reduce_mean(tf.sign(truePreds))\n",
    "\n",
    "def dra(obsPreds, basePreds): # observe/baseline predictions (representing fake/true data)\n",
    "    meanBase = K.mean(basePreds)\n",
    "    return tf.nn.sigmoid(obsPreds - meanBase)\n",
    "\n",
    "def discLoss(truePreds, fakePreds, epsilon=eps):\n",
    "    trueLoss = K.mean(tf.nn.softplus(-truePreds)) # -log(sigmoid(real_scores_out))\n",
    "    fakeLoss = K.mean(tf.nn.softplus(fakePreds)) # -log(1-sigmoid(fake_scores_out))\n",
    "    classLoss = trueLoss + fakeLoss\n",
    "    return classLoss\n",
    "\n",
    "def genLoss(fakePreds, epsilon=eps):\n",
    "    classLoss = K.mean(tf.nn.softplus(-fakePreds))\n",
    "    return classLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civilian-disposal",
   "metadata": {},
   "source": [
    "#### Regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuck-prevention",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# path length reg.\n",
    "@tf.function\n",
    "def pplReg(a=0.0):\n",
    "    pplbatchSize = batchSize // 2\n",
    "    y = tf.random.normal((pplbatchSize, imgSize, imgSize, 3))\n",
    "    noise = tf.random.uniform((pplbatchSize, imgSize, imgSize, 1))\n",
    "    z = tf.random.normal((pplbatchSize, zdim))\n",
    "    \n",
    "    w = mapper(z, training=True)\n",
    "    ws = [w for _ in range(nBlocks+1)]\n",
    "    preds = generator([*ws, noise], training=True)\n",
    "    jacLite = tf.math.reduce_sum(preds * y)\n",
    "    \n",
    "    jac = tf.gradients(jacLite, w)[0]\n",
    "    norm = tf.norm(jac)\n",
    "    return K.mean(tf.square(norm - tf.cast(a, tf.float32))), norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atomic-strap",
   "metadata": {},
   "source": [
    "#### FID function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjacent-helicopter",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import sqrtm\n",
    "\n",
    "allRealFeatures = None\n",
    "\n",
    "# turn TF tensor outputs into numpy array outputs\n",
    "def toNp(*args):\n",
    "    ret = []\n",
    "    for i in args:\n",
    "        meanVal = i\n",
    "        try:\n",
    "            meanVal = i.numpy()\n",
    "        except:\n",
    "            pass\n",
    "        ret.append(meanVal)\n",
    "    return ret\n",
    "\n",
    "def calculate_fid():\n",
    "    global allRealFeatures\n",
    "    \n",
    "    def crunch(batch, bs=64):\n",
    "        z1, z2 = npr.randn(2, bs, zdim)\n",
    "        noise = npr.randn(bs, imgSize, imgSize, 1)\n",
    "        w1 = mapper(z1, training=False)\n",
    "        w2 = mapper(z2, training=False)\n",
    "        ws = [w1 for _ in range(3)] + [w2 for _ in range(4)]\n",
    "        fakes = generator([*ws, noise], training=False)\n",
    "        fakeFeatures = inception(fakes/2+0.5, training=False)\n",
    "        realFeatures = inception(batch/2+0.5, training=False)\n",
    "        return fakeFeatures.numpy(), realFeatures.numpy()\n",
    "    def crunchLite(batch, bs=64):\n",
    "        z1, z2 = npr.randn(2, bs, zdim)\n",
    "        noise = npr.randn(bs, imgSize, imgSize, 1)\n",
    "        w1 = mapper(z1, training=False)\n",
    "        w2 = mapper(z2, training=False)\n",
    "        ws = [w1 for _ in range(3)] + [w2 for _ in range(4)]\n",
    "        fakes = generator([*ws, noise], training=False)\n",
    "        fakeFeatures = inception(fakes/2+0.5, training=False)\n",
    "        return fakeFeatures.numpy(), -1\n",
    "    \n",
    "    K.clear_session()\n",
    "    bs = 16\n",
    "    expandM = bs * (m//bs)\n",
    "    crunchFunc = crunchLite\n",
    "    if allRealFeatures == None:\n",
    "        crunchFunc = crunch\n",
    "        allRealFeatures = np.zeros((expandM, 2048))\n",
    "        \n",
    "    allFakeFeatures = np.zeros((expandM, 2048))\n",
    "    for batchS in tqdm(range(0, expandM, bs)):\n",
    "        batch = reals[batchS: batchS + bs]\n",
    "        fakeFeatures, realFeatures = crunchFunc(batch, bs=bs)\n",
    "        allFakeFeatures[batchS: batchS + bs] = fakeFeatures\n",
    "        \n",
    "        if crunchFunc == crunch:\n",
    "            allRealFeatures[batchS: batchS + bs] = realFeatures\n",
    "        \n",
    "    # calculate mean and covariance statistics\n",
    "    fakeMean, fakeStd = np.mean(allFakeFeatures, axis=0), np.cov(allFakeFeatures, rowvar=False)\n",
    "    realMean, realStd = np.mean(allRealFeatures, axis=0), np.cov(allRealFeatures, rowvar=False)\n",
    "    # calculate sum squared difference between means\n",
    "    ssdiff = np.sum((fakeMean - realMean) ** 2.0)\n",
    "    # calculate sqrt of product between cov\n",
    "    covmean = sqrtm(np.dot(fakeStd, realStd))\n",
    "    if np.iscomplexobj(covmean):\n",
    "        covmean = covmean.real\n",
    "    # calculate score\n",
    "    fid = ssdiff + np.trace(fakeStd + realStd - 2.0 * covmean)\n",
    "    K.clear_session()\n",
    "    return fid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-religious",
   "metadata": {},
   "source": [
    "#### Step function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corporate-memorial",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "One training step for the GAN.\n",
    "Args:\n",
    "batch - input batch of real images\n",
    "p - probability of augmenting image\n",
    "pplEMA - skip PPL reg. if it is -1, else use the value for regularization\n",
    "useGP - skip R1 gradient penalty if it is -1\n",
    "'''\n",
    "@tf.function\n",
    "def trainStep(batch, p, pplEMA=-tf.ones(()), useGP=-tf.ones(())):\n",
    "    def genImgs():\n",
    "        z1 = tf.random.normal([batchSize, zdim])\n",
    "        z2 = tf.random.normal([batchSize, zdim])\n",
    "        noise = tf.random.normal([batchSize, imgSize, imgSize, 1])\n",
    "\n",
    "        w1 = z1; w2 = z2\n",
    "        w1 = mapper(z1, training=True)\n",
    "        w2 = tf.cond(tf.random.uniform(()) < 0.9, lambda: mapper(z2, training=True), lambda: w1)\n",
    "        splitInd = npr.randint(nBlocks+1)\n",
    "        ws = [w1 for _ in range(splitInd)] + [w2 for _ in range(nBlocks+1-splitInd)]\n",
    "        fakes = generator([*ws, noise], training=True)\n",
    "        return fakes\n",
    "    \n",
    "    fakes = genImgs()\n",
    "    augBatch = aug(batch, p)\n",
    "    augFakes = aug(fakes, p)\n",
    "    truePreds = discriminator(augBatch, training=True)\n",
    "    fakePreds = discriminator(augFakes, training=True)\n",
    "\n",
    "    gpWeight = 16 * 10 / 2\n",
    "    gploss = tf.cond(useGP >= 0, lambda: gpWeight * K.mean((tf.reduce_sum(tf.square(tf.gradients(truePreds, [augBatch])[0]), axis=[1,2,3]))), lambda: 0.0)\n",
    "\n",
    "    dloss = discLoss(truePreds, fakePreds) + gploss\n",
    "    rtBatch = rt(truePreds)\n",
    "    \n",
    "    fakes = genImgs()\n",
    "    augFakes = aug(fakes, p)\n",
    "    fakePreds = discriminator(augFakes, training=True)\n",
    "\n",
    "    pplWeight = 8 * 2 / (imgSize * imgSize * (nBlocks + 1))\n",
    "    pplLoss, pplNorm = tf.cond(pplEMA >= 0, lambda: pplReg(pplEMA), lambda: (0.0, 0.0))\n",
    "    pplLoss = pplWeight * pplLoss\n",
    "    gloss = genLoss(fakePreds) + pplLoss\n",
    "    \n",
    "    dGrad = tf.gradients(dloss, discriminator.trainable_variables)\n",
    "    discOpt.apply_gradients(zip(dGrad, discriminator.trainable_variables))\n",
    "\n",
    "    gGrad = tf.gradients(gloss, generator.trainable_variables)\n",
    "    genOpt.apply_gradients(zip(gGrad, generator.trainable_variables))\n",
    "    \n",
    "    mGrad = tf.gradients(gloss, mapper.trainable_variables)\n",
    "    mapOpt.apply_gradients(zip(mGrad, mapper.trainable_variables))\n",
    "    \n",
    "    return dloss, gploss, gloss, rtBatch, pplLoss, pplNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contrary-badge",
   "metadata": {},
   "source": [
    "#### Gradient visualization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-thompson",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def retGrads():\n",
    "    z1 = tf.random.normal([1, zdim])\n",
    "    z2 = tf.random.normal([1, zdim])\n",
    "    noise = tf.random.normal([1, imgSize, imgSize, 1])\n",
    "    randImg = tf.convert_to_tensor(reals[npr.randint(0, reals.shape[0])][np.newaxis])\n",
    "\n",
    "    with tf.GradientTape() as tapeReal, tf.GradientTape() as tapeFake:\n",
    "        w1 = z1; w2 = z2\n",
    "        w1 = mapper(z1, training=False)\n",
    "        w2 = mapper(z2, training=False)\n",
    "        ws = [w1 for _ in range(3)] + [w2 for _ in range(4)]\n",
    "        tapeReal.watch(randImg)\n",
    "        fakes = generator([*ws, noise], training=False)\n",
    "        tapeFake.watch(fakes)\n",
    "        truePreds = discriminator(randImg, training=False)\n",
    "        fakePreds = discriminator(fakes, training=False)\n",
    "        dloss = discLoss(truePreds, fakePreds)\n",
    "\n",
    "    realGrad = tapeReal.gradient(dloss, randImg)[0]\n",
    "    fakeGrad = tapeFake.gradient(dloss, fakes)[0]\n",
    "    realNorm = tf.norm(realGrad)\n",
    "    fakeNorm = tf.norm(fakeGrad)\n",
    "    return realGrad.numpy(), fakeGrad.numpy(), realNorm.numpy(), fakeNorm.numpy(), randImg[0].numpy(), fakes[0].numpy(), truePreds.numpy(), fakePreds.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "median-orlando",
   "metadata": {},
   "source": [
    "#### Train functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-ivory",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def train(epochs=None, steps=None, n=4):\n",
    "    global p, pplNorms, pplEMA\n",
    "    gc.collect()\n",
    "    rtBatches = 0\n",
    "    \n",
    "    if epochs != None:\n",
    "        for i in range(epochs):\n",
    "            gc.collect()\n",
    "            dcost, gpcost, gcost = 0, 0, 0\n",
    "            pplSum = 0\n",
    "            rtSum, pplCost = 0, 0\n",
    "            batchNum = 0\n",
    "            for batch in ds:\n",
    "                pTensor = tf.convert_to_tensor(p, dtype=tf.float32)\n",
    "                batch = reals[npr.randint(0, m, (batchSize,))]\n",
    "                if batchNum % 16 == 0:\n",
    "                    vals = toNp(*trainStep(batch, pTensor, tf.convert_to_tensor(pplEMA), useGP=tf.ones(())))\n",
    "                elif batchNum % 8 == 0:\n",
    "                    vals = toNp(*trainStep(batch, pTensor, tf.convert_to_tensor(pplEMA)))\n",
    "                else:\n",
    "                    vals = toNp(*trainStep(batch, pTensor))\n",
    "                dloss, gploss, gloss, rtBatch, pplLoss, pplNorm = vals\n",
    "\n",
    "                if pplNorm != 0:\n",
    "                    pplEMA = 0.01 * pplNorm + 0.99 * pplEMA\n",
    "                \n",
    "                rtBatches += rtBatch\n",
    "                if batchNum % n == 0:\n",
    "                    p += pStep * np.sign(rtBatches/n - 0.6)\n",
    "                    p = round(min(max(p, 0), 1), 6) % 0.8\n",
    "                    rtBatches = 0\n",
    "                batchNum += 1\n",
    "                dcost += dloss; gpcost += gploss; gcost += gloss; rtSum += rtBatch; pplCost += pplLoss; pplSum += pplNorm\n",
    "            \n",
    "            dcosts.append(dcost)\n",
    "            gcosts.append(gcost)\n",
    "            gpcosts.append(gpcost)\n",
    "            pplNorms.append(round(pplSum / batchNum, 4))\n",
    "            ps.append(p)\n",
    "            rts.append(rtBatch)\n",
    "            print('Epoch: {} | D Cost: {} | GP Cost: {} | G Cost: {}'.format(i, dcost, gpcost, gcost), end = ' | ')\n",
    "            print('P(aug): {} | Rt: {} | PPL Norm: {} | PPL Loss: {}'.format(p, round(rtSum / batchNum, 4), round(pplSum / batchNum, 4), round(pplCost, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepted-glenn",
   "metadata": {},
   "source": [
    "#### Display function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-formula",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "rows, cols = 1, 4\n",
    "\n",
    "'''\n",
    "Display generated images as well as a summary of model metrics.\n",
    "Args:\n",
    "z1/z2 - latent input vector 1/2\n",
    "noise - noise input\n",
    "verbose - 5-element list saying which metrics to calculate and print out\n",
    "verbose[0] - FID score\n",
    "verbose[1] - D(G(z)) - discriminator predictions on generated images\n",
    "verbose[2] - D(x) - discriminator predictions on real images\n",
    "verbose[3/4] - D/G Loss\n",
    "verbose=True/1: print everything\n",
    "verbose=False/0: print nothing\n",
    "'''\n",
    "\n",
    "def display(z1, z2, noise, verbose=True):\n",
    "    gc.collect()\n",
    "    fig = plt.figure(figsize=(30, 5))\n",
    "    axes = fig.subplots(rows, cols)\n",
    "    \n",
    "    z1[0] = constZ; z2[0] = constZ; noise[0] = constNoise\n",
    "    assert z1.shape == (rows * cols, zdim)\n",
    "    assert z2.shape == (rows * cols, zdim)\n",
    "    assert noise.shape == (rows * cols, imgSize, imgSize, 1)\n",
    "        \n",
    "    randInds = npr.randint(0, reals.shape[0], (rows*cols,))\n",
    "    \n",
    "    w1 = z1; w2 = z2\n",
    "    w1 = mapper(z1, training=False)\n",
    "    w2 = mapper(z2, training=False)\n",
    "    ws = [w1 for _ in range(3)] + [w2 for _ in range(4)]\n",
    "    preds = generator([*ws, noise], training=False)\n",
    "    df = discriminator(preds, training=False)\n",
    "    dr = discriminator(reals[randInds], training=False)\n",
    "    if type(verbose) == type(True):\n",
    "        verbose = [verbose for i in range(5)]\n",
    "    if type(verbose) == int:\n",
    "        if verbose == 0:\n",
    "            verbose = [False for i in range(5)]\n",
    "        elif verbose == 1:\n",
    "            verbose = [False, False, False, True, True]\n",
    "        elif verbose == 2:\n",
    "            verbose = [False, True, True, True, True]\n",
    "        elif verbose == 3:\n",
    "            verbose = [True for i in range(5)]\n",
    "            \n",
    "    if verbose[1]:\n",
    "        print('D(G(z)) (lower = better disc):', np.mean(df))\n",
    "    if verbose[2]:\n",
    "        print('D(x) (higher = better disc):', np.mean(dr))\n",
    "    if verbose[3]:\n",
    "        print('D Loss:', discLoss(dr, df))\n",
    "    if verbose[4]:\n",
    "        print('G Loss:', genLoss(df))\n",
    "    \n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            axes[j].imshow(preds[i*cols + j] / 2 + 0.5)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    if verbose[0]:\n",
    "        fid = round(calculate_fid(), 4)\n",
    "        print('FID:', fid)\n",
    "        fids.append(fid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precious-consultation",
   "metadata": {},
   "source": [
    "#### Save model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interim-walnut",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Save current state of model, overwriting past state of model on disk.\n",
    "Args:\n",
    "askInp - require user to place input before saving models - protects user from accidentally overwriting models with a collapsed model\n",
    "'''\n",
    "def save_models(askInp=True):\n",
    "    if askInp:\n",
    "        input()\n",
    "    \n",
    "    os.chdir(modelPath)\n",
    "    generator.save_weights('genWeights.h5')\n",
    "    discriminator.save_weights('discWeights.h5')\n",
    "    mapper.save_weights('mapWeights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shaped-tracy",
   "metadata": {},
   "source": [
    "#### Train GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governmental-lithuania",
   "metadata": {},
   "outputs": [],
   "source": [
    "constZ = npr.randn(zdim,)\n",
    "constNoise = npr.randn(imgSize, imgSize, 1)\n",
    "epoch = 0\n",
    "\n",
    "while True:\n",
    "    if type(reals) != np.ndarray or type(ds) == type(None):\n",
    "        loadData()\n",
    "    \n",
    "    sess = timeIt('Training')\n",
    "    display(z1=npr.randn(rows * cols, zdim), z2=npr.randn(rows * cols, zdim), noise=npr.randn(rows * cols, imgSize, imgSize, 1), verbose=True)\n",
    "    \n",
    "    train(epochs=5)\n",
    "    loadData()\n",
    "    epoch += 1\n",
    "    sess.close()\n",
    "    save_models(askInp=False)\n",
    "    np.save(os.path.join(modelPath, 'p.npy'), p) # save p value for future training if training on servers with time limits like Paperspace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sorted-attack",
   "metadata": {},
   "source": [
    "#### Visualize gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fancy-compact",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if type(reals) != np.ndarray or type(ds) == type(None):\n",
    "    #loadData()\n",
    "    reals = np.load(os.path.join(datasetPath, 'imgs.npy'))\n",
    "    m = batchSize * (reals.shape[0] // batchSize)\n",
    "    reals = reals[:m].astype(np.float32)\n",
    "\n",
    "    assert reals.shape[0] % batchSize == 0\n",
    "    assert type(reals) == np.ndarray\n",
    "    ds = (tf.data.Dataset.from_tensor_slices(tf.cast(reals, tf.float32)).shuffle(3000).batch(batchSize))\n",
    "    ds = ds.prefetch(AUTO)\n",
    "    gc.collect()\n",
    "\n",
    "dGrad, gGrad, dNorm, gNorm, img, fake, truePreds, fakePreds = retGrads()\n",
    "dGrad = np.sum(dGrad, axis=2)\n",
    "gGrad = np.sum(gGrad, axis=2)\n",
    "print('D(x): {} | D(G(z)): {}'.format(truePreds, fakePreds))\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(20, 20))\n",
    "dGrad = (dGrad - np.min(dGrad)) / (np.max(dGrad) - np.min(dGrad) + eps)\n",
    "gGrad = (gGrad - np.min(gGrad)) / (np.max(gGrad) - np.min(gGrad) + eps)\n",
    "axes[0][0].imshow(img/2+0.5)\n",
    "axes[0][1].imshow(fake/2+0.5)\n",
    "axes[1][0].imshow(dGrad)\n",
    "axes[1][0].set_title('Real Grad; Norm: {}'.format(round(dNorm, 4)))\n",
    "axes[1][1].imshow(gGrad)\n",
    "axes[1][1].set_title('Fake Grad; Norm: {}'.format(round(gNorm, 4)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ethical-scanning",
   "metadata": {},
   "source": [
    "#### Visualize mapping activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anonymous-resolution",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "z = npr.randn(1, zdim)\n",
    "w = mapper.predict(z)\n",
    "plt.imshow(z[0].reshape(16, 16))\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "plt.imshow(w[0].reshape(16, 16))\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vertical-salon",
   "metadata": {},
   "source": [
    "#### See generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peaceful-jurisdiction",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    constZ1s\n",
    "except Exception as e:\n",
    "    constZ1s = npr.randn(rows*cols, zdim)\n",
    "    constZ2s = npr.randn(rows*cols, zdim)\n",
    "    constNoises = npr.randn(rows * cols, imgSize, imgSize, 1)\n",
    "\n",
    "'''\n",
    "if z1s commented out, same content, different styles\n",
    "if z2s commented out, different content, same styles\n",
    "if noise = 0, undesirably smooth faces but just a test to make sure styles are working properly\n",
    "'''\n",
    "for i in range(5): \n",
    "    constZ1s = npr.randn(rows * cols, zdim)\n",
    "    #constZ2s = npr.randn(rows * cols, zdim)\n",
    "    constNoises = npr.randn(rows * cols, imgSize, imgSize, 1) * 0\n",
    "    display(z1=constZ1s, z2=constZ2s, noise=constNoises, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blind-alfred",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    constZ1s\n",
    "except Exception as e:\n",
    "    constZ1s = npr.randn(rows*cols, zdim)\n",
    "    constZ2s = npr.randn(rows*cols, zdim)\n",
    "    constNoises = npr.randn(rows * cols, imgSize, imgSize, 1)\n",
    "    \n",
    "fig, axes = plt.subplots(nrows=2, ncols=cols, figsize=(30, 15))\n",
    "\n",
    "z1 = constZ1s; z2 = constZ2s; noise = constNoises\n",
    "\n",
    "randInds = npr.randint(0, reals.shape[0], (rows*cols,))\n",
    "\n",
    "w1 = z1; w2 = z2\n",
    "ws = [w1 for i in range(3)] + [w2 for i in range(4)]\n",
    "preds = generator([*ws, noise], training=False)\n",
    "\n",
    "for i in range(cols):\n",
    "    axes[0][i].imshow(preds[i] / 2 + 0.5)\n",
    "    \n",
    "w1 = mapper(z1, training=False)\n",
    "w2 = mapper(z2, training=False)\n",
    "ws = [w1 for i in range(3)] + [w2 for i in range(4)]\n",
    "preds = generator([*ws, noise], training=False)\n",
    "\n",
    "for i in range(cols):\n",
    "    axes[1][i].imshow(preds[i] / 2 + 0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-planet",
   "metadata": {},
   "source": [
    "#### See metrics over training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worthy-spokesman",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(20, 4))\n",
    "pltX = range(len(dcosts))\n",
    "axes[0].plot(pltX, dcosts); axes[0].set_title('D Loss')\n",
    "axes[1].plot(pltX, gcosts); axes[1].set_title('G Loss')\n",
    "axes[2].plot(pltX, gpcosts); axes[2].set_title('GP')\n",
    "plt.show()\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20, 4))\n",
    "axes[0].plot(pltX, ps); axes[0].set_title('Evolution of P(aug) over training')\n",
    "axes[1].plot(pltX, rts); axes[1].set_title('Evolution of r_t')\n",
    "plt.show()\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(20, 8))\n",
    "axes.set_title('D Loss (Blue) vs. G Loss (Orange)')\n",
    "axes.plot(pltX, dcosts, color='blue')\n",
    "axes.plot(pltX, gcosts, color='orange')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "armed-mistress",
   "metadata": {},
   "source": [
    "#### Epilogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-naples",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "save_models(askInp=True)\n",
    "np.save(os.path.join(modelPath, 'p.npy'), p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "british-alexander",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "K.clear_session()\n",
    "#del generator, discriminator, mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fallen-competition",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
